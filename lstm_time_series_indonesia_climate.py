# -*- coding: utf-8 -*-
"""LSTM Time Series Indonesia Climate

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q6fGfmq5yGPtitCBHU5ZOOuzwH1guXs3

Karta Kusuma

Sumber Dataset: https://www.kaggle.com/datasets/greegtitan/indonesia-climate
"""

import pandas as pd

df = pd.read_csv('climate_data.csv')
df

df = df[['date', 'Tavg']]
df

df.isnull().sum()

df.fillna(df['Tavg'].mean(), inplace=True)
df.info()

date = df['date']
temp = df['Tavg']

import matplotlib.pyplot as plt

plt.figure(figsize=(15,5))
plt.plot(date, temp)
plt.title('Temperature in Indonesia', fontsize=20)
plt.xlabel('Date')
plt.ylabel('Temperature')

from sklearn.model_selection import train_test_split

temp_train, temp_test, date_train, date_test = train_test_split(temp, date, test_size=0.2, random_state=0, shuffle=False)

import tensorflow as tf

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

wd_temp_train = windowed_dataset(temp_train, window_size=60, batch_size=100, shuffle_buffer=1000)
wd_temp_test = windowed_dataset(temp_test, window_size=60, batch_size=100, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv1D(
        filters=32, 
        kernel_size=5, 
        strides=1, 
        padding='causal', 
        activation='relu', 
        input_shape=[None, 1]
    ),
    tf.keras.layers.LSTM(60, return_sequences=True),
    tf.keras.layers.LSTM(60),
    tf.keras.layers.Dense(30, activation='relu'),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(1)
])

model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=tf.keras.optimizers.SGD(learning_rate=1.0000e-04, momentum=0.9),
    metrics=['mae']
)

val_stop = (temp.max() - temp.min()) * 0.1
val_stop

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < val_stop and logs.get('val_mae') < val_stop):
      print('\nMAE value is < 10% of data\'s scale')
      self.model.stop_training = True
callback = myCallback()

history = model.fit(wd_temp_train, epochs=100, validation_data=wd_temp_test, callbacks=[callback])

plt.plot(history.history['mae'])
plt.plot(history.history['val_mae'])
plt.title('MAE')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

